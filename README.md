# ğŸ‘ï¸ Real-Time Video Analytics Pipeline

    

Bu proje, gÃ¼venlik kameralarÄ± ve video akÄ±ÅŸlarÄ± iÃ§in geliÅŸtirilmiÅŸ; **modÃ¼ler**, **Ã¶lÃ§eklenebilir** ve **daÄŸÄ±tÄ±ma hazÄ±r** bir bilgisayarlÄ± gÃ¶rÃ¼ (Computer Vision) hattÄ±dÄ±r (pipeline).

**Temel Yetenekler:**

  * ğŸš€ **Nesne Tespiti:** YOLOv8 (State-of-the-Art)
  * ğŸ¯ **Nesne Takibi:** SORT (Kalman Filter + Hungarian Algorithm)
  * ğŸ“Š **Analitik:** GerÃ§ek zamanlÄ± FPS, nesne sayÄ±mÄ± ve ROI analizi.
  * ğŸ¤– **Sentetik Veri:** Text-to-Video modelleri ile uÃ§ durum (edge-case) testi.
  * ğŸŒ **Servis:** FastAPI tabanlÄ± REST API.

-----

## ğŸ—ï¸ Mimari ve TasarÄ±m Prensipleri

Proje, **"Separation of Concerns"** (Ä°lgi AlanlarÄ±nÄ±n AyrÄ±mÄ±) ve **"Dependency Injection"** prensipleri gÃ¶zetilerek geliÅŸtirilmiÅŸtir.

### 1\. ModÃ¼ler YapÄ± (Dependency Injection)

`Pipeline` sÄ±nÄ±fÄ±, `Detector` veya `Tracker` sÄ±nÄ±flarÄ±na sÄ±kÄ± sÄ±kÄ±ya baÄŸlÄ± (tightly coupled) deÄŸildir. Bu bileÅŸenler `main.py` veya `app.py` iÃ§erisinde oluÅŸturulup Pipeline'a enjekte edilir.

  * **AvantajÄ±:** Bu sayede gelecekte YOLO yerine **Faster-RCNN** veya SORT yerine **DeepSORT** kullanmak istenirse, sadece ilgili sÄ±nÄ±fÄ± deÄŸiÅŸtirmek yeterlidir; Pipeline mantÄ±ÄŸÄ±na dokunulmaz. AyrÄ±ca **Unit Test** yazarken Mock objelerle test etmeyi kolaylaÅŸtÄ±rÄ±r.

### 2\. GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme (Preprocessing) YaklaÅŸÄ±mÄ±

  * **ROI (Region of Interest):** KullanÄ±cÄ±, videonun sadece belirli bir yÃ¼zdelik alanÄ±nÄ± (Ã¶rn: `%20` ile `%80` arasÄ±) iÅŸleyebilir.
      * *Neden?* FPS artÄ±ÅŸÄ± saÄŸlar, iÅŸlemciyi rahatlatÄ±r ve modelin ilgisiz arka plana odaklanmasÄ±nÄ± engelleyerek **False Positive** oranÄ±nÄ± dÃ¼ÅŸÃ¼rÃ¼r.
  * **Neden Blur/Grayscale Yok?** YOLO gibi modern CNN (Convolutional Neural Network) modelleri, Ã¶zellik Ã§Ä±karÄ±mÄ± (feature extraction) sÄ±rasÄ±nda gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± zaten direnÃ§lidir. Geleneksel yÃ¶ntemlerdeki gibi (Canny Edge vb.) Ã¶n iÅŸlemeye ihtiyaÃ§ duymazlar. Gereksiz iÅŸlem yÃ¼kÃ¼nden kaÃ§Ä±nÄ±lmÄ±ÅŸtÄ±r.

### 3\. Takip AlgoritmasÄ± (SORT Implementation)

Bu projede Alex Bewley'in orijinal SORT algoritmasÄ± referans alÄ±nmÄ±ÅŸtÄ±r. Ancak kod kopyalanmamÄ±ÅŸ, projenin OOP yapÄ±sÄ±na ve **`Detection`** veri sÄ±nÄ±fÄ±na uygun ÅŸekilde **refactor** edilmiÅŸtir.

  * **Bilinen KÄ±sÄ±tlar:** SORT sadece konum ve hÄ±z (Motion-based) takibi yapar. Uzun sÃ¼reli kapanmalarda (Occlusion) gÃ¶rsel hafÄ±zasÄ± olmadÄ±ÄŸÄ± iÃ§in **ID Switching** (Kimlik deÄŸiÅŸimi) yaÅŸanabilir.
  * *Not:* Production ortamÄ±nda donanÄ±m elverirse DeepSORT entegrasyonu planlanmÄ±ÅŸtÄ±r.

-----

## ğŸ› ï¸ Kurulum (Installation)

Proje hem yerel geliÅŸtirme ortamÄ±nda (Local Developer) hem de Docker konteynerinde Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

### Ã–n Gereksinimler

  * **Python:** 3.9 veya Ã¼zeri (Type hinting `list[str]` ve `| None` desteÄŸi iÃ§in).
  * **GPU:** NVIDIA GPU ve gÃ¼ncel sÃ¼rÃ¼cÃ¼ler (Ã–nerilen).

-----

### A. GeliÅŸtirici Modu (Local Setup)

Bu mod, kodu geliÅŸtirmek ve debug etmek iÃ§indir.

1.  **Repo'yu klonlayÄ±n ve dizine girin:**

    ```bash
    git clone https://github.com/yourusername/vision-pipeline.git
    cd vision-pipeline
    ```

2.  **Sanal ortam oluÅŸturun:**

    ```bash
    python -m venv venv
    # Windows:
    venv\Scripts\activate
    # Linux/Mac:
    source venv/bin/activate
    ```

3.  **âš ï¸ Kritik AdÄ±m: GPU DesteÄŸi (PyTorch)**
    `requirements.txt` dosyasÄ± donanÄ±m baÄŸÄ±msÄ±zdÄ±r. GPU hÄ±zlandÄ±rmasÄ±ndan faydalanmak iÃ§in bilgisayarÄ±nÄ±zdaki CUDA sÃ¼rÃ¼mÃ¼ne uygun PyTorch'u manuel kurmalÄ±sÄ±nÄ±z.
    *(Ã–rnek: CUDA 12.x iÃ§in)*

    ```bash
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    ```

    *EÄŸer GPU yoksa bu adÄ±mÄ± atlayabilirsiniz, CPU sÃ¼rÃ¼mÃ¼ otomatik kurulacaktÄ±r.*

4.  **DiÄŸer baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:**

    ```bash
    pip install -r requirements.txt
    ```

-----

### B. Konteyner Modu (Docker Deployment)

Bu mod, API servisini izole bir ortamda sunmak iÃ§indir.

**âš ï¸ Ã–NEMLÄ°:** Docker iÃ§inde GPU kullanabilmek iÃ§in host makinede sadece Docker deÄŸil, **NVIDIA Container Toolkit** de kurulu olmalÄ±dÄ±r.

1.  **Ä°majÄ± OluÅŸturun (Build):**
    Docker imajÄ±, CUDA 12.1 destekli resmi PyTorch imajÄ±nÄ± baz alÄ±r. Manuel Torch kurulumu gerekmez.

    ```bash
    docker build -t vision-app .
    ```

2.  **Konteyneri BaÅŸlatÄ±n (Run):**
    GPU eriÅŸimi vererek API'yi 8000 portunda baÅŸlatÄ±n.

    ```bash
    docker run --gpus all -p 8000:8000 vision-app
    ```

    *EÄŸer `nvidia-container-toolkit` yoksa `--gpus all` parametresini kaldÄ±rÄ±n (CPU modunda Ã§alÄ±ÅŸÄ±r).*

-----

## ğŸš€ KullanÄ±m (Usage)

### 1\. Komut SatÄ±rÄ± ArayÃ¼zÃ¼ (CLI)

VideolarÄ± terminal Ã¼zerinden iÅŸlemek iÃ§in `main.py` kullanÄ±lÄ±r. Ã‡Ä±ktÄ±lar `data/output/` altÄ±na, tarih damgalÄ± klasÃ¶rler halinde kaydedilir (**Artifact Encapsulation**).

```bash
# Temel KullanÄ±m
python src/main.py --input_path data/input/videos/sample.mp4

# GeliÅŸmiÅŸ KullanÄ±m (ROI Belirleme)
# ROI FormatÄ±: x_start y_start width height (YÃ¼zdelik: 0.0 - 1.0 arasÄ±)
# Ã–rn: %10 soldan, %20 Ã¼stten baÅŸla, %50 geniÅŸlik ve %50 yÃ¼kseklik al.
python src/main.py --input my_video --roi 0.1 0.2 0.5 0.5 --conf 0.6
```

### 2\. REST API (FastAPI)

Sistemi bir mikroservis olarak kullanmak iÃ§in `app.py` veya Docker kullanÄ±lÄ±r.

  * **BaÅŸlatma:** `python src/app.py`
  * **DokÃ¼mantasyon:** TarayÄ±cÄ±da `http://localhost:8000/docs` adresine giderek Swagger UI Ã¼zerinden video yÃ¼kleyip test edebilirsiniz.

-----

## ğŸ¤– Sentetik Veri Ãœretimi (GenAI)

Modelin zorlu koÅŸullardaki (Ã¶rn: karanlÄ±k, sisli fabrika ortamÄ±) baÅŸarÄ±sÄ±nÄ± test etmek iÃ§in **Text-to-Video** teknolojisi kullanÄ±lmÄ±ÅŸtÄ±r.

  * **Script:** `src/data_generation/generator.py`
  * **Model:** ModelScope (damo-vilab/text-to-video-ms-1.7b)
  * **KullanÄ±m:**
    ```python
    python src/data_generation/generator.py
    ```
    *Not: Bu iÅŸlem yÃ¼ksek VRAM (GPU HafÄ±zasÄ±) gerektirir. DonanÄ±m kÄ±sÄ±tlarÄ±nda Luma/RunwayML gibi online araÃ§lar alternatif olarak kullanÄ±labilir.*

-----

## ğŸ§ª Testler

Proje, birim (unit) ve entegrasyon testlerini iÃ§erir. Mocking kullanÄ±larak, aÄŸÄ±r modelleri yÃ¼klemeden pipeline mantÄ±ÄŸÄ± test edilmiÅŸtir.

```bash
pytest
```

-----

## ğŸ”® Gelecek PlanlarÄ± (Future Work)

  * [ ] **DeepSORT / ByteTrack:** ID Switching sorununu azaltmak iÃ§in gÃ¶rsel Ã¶zellik (Re-ID) kullanan tracker entegrasyonu.
  * [ ] **Model SeÃ§imi:** KullanÄ±cÄ±nÄ±n API isteÄŸiyle model boyutunu (yolov8n, yolov8x) seÃ§ebilmesi.
  * [ ] **Database:** Analitik verilerinin (AnalyticsManager) PostgreSQL/MongoDB'ye yazÄ±lmasÄ±.

-----

## âš–ï¸ Lisans ve Etik

  * Bu proje MIT lisansÄ± ile sunulmuÅŸtur.
  * KullanÄ±lan YOLOv8 modeli AGPL-3.0, SORT algoritmasÄ± GPL-3.0 lisanslarÄ±na tabidir.
  * Sentetik veriler test amaÃ§lÄ± Ã¼retilmiÅŸtir, gerÃ§ek kiÅŸilerin gizliliÄŸini ihlal etmez.